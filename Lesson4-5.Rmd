---
title: 'Time Series: A First Course with Bootstrap Starter'
output:
  html_document:
    df_print: paged
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Users/neide/OneDrive/Documents/GitHub/BEwebinar/Data')
```

# Lesson 4-5: Time Series Prediction

- We apply projection techniques to predict (or forecast) time series.

## Paradigm 4.5.1. The Conditional Expectation

- Let $\{ X_t \}$ be a weakly stationary time series in ${\mathbb L}_2$. 
- Suppose for some $t > n$ we wish to predict $X_t$ from $X_1, \ldots, X_n$. The predictor is denoted $\widehat{X}_t$.
- We want the prediction error to have minimal mean square:
\[
  {\mathbb E} [ {( \widehat{X}_t - X_t)}^2]
\]
is the Mean Squared Error (MSE).  
- Theorem 4.5.2. The minimal MSE predictor is the conditional expectation:
\[
 \widehat{X}_t = {\mathbb E} [ X_t \vert X_1, \ldots, X_n].
\]

## Example 4.5.6. Order One Autoregression

- Let $\{ X_t \}$ be an AR(1), i.e., $X_t = \phi X_{t-1} + Z_t$ with $\{ Z_t \}$ i.i.d. $(0,\sigma^2)$. 
- Assume $Z_t$ is independent of $X_s$ for all $s < t$. 

### One-step ahead prediction

- Consider predicting one-step ahead: we want $\widehat{X}_{n+1}$, given $X_1, \ldots, X_n$.
- We calculate the conditional expectation:
\begin{align*}
  {\mathbf E} [ X_{n+1} \vert X_1, \ldots, X_n] & = 
     {\mathbf E} [ \phi X_n + Z_{n+1} \vert X_1, \ldots, X_n] \\
     & = \phi \,  {\mathbf E} [ X_{n} \vert X_1, \ldots, X_n]
      +  {\mathbf E} [ Z_{n+1} \vert X_1, \ldots, X_n] \\
      & = \phi \, X_n + 0.
\end{align*}
 This uses linearity of conditional expectation, and independence of $Z_{n+1}$ from $X_1, \ldots, X_n$.
- The prediction error is then
\[
  X_{n+1} - \widehat{X}_{n+1} = X_{n+1} - \phi \, X_n = Z_{n+1},
\]
 so that the MSE is ${\mathbb E} [ Z_{n+1}^2] = \sigma^2$.

```{r}
set.seed(123)
n <- 100
z <- rnorm(n)
x <- rep(0,n)
xhat <- rep(0,n)
phi <- .9
x0 <- 0
x[1] <- x0 + z[1]
for(t in 2:n) 
{
  x[t] <- phi*x[t-1] + z[t] 
  xhat[t] <- phi*x[t-1]
}
plot(ts(x),xlab="Time",ylab="")
lines(ts(xhat),col=2)
```

### Two-step ahead prediction

- Consider predicting two steps ahead: we want $\widehat{X}_{n+2}$, given $X_1, \ldots, X_n$.
- Note that by applying the AR(1) recursion twice we can write
\[
 X_{n+2} = \phi^2 X_n + \phi Z_{n+1} + Z_{n+2}.
 \]
- Hence the conditional expectation is
  \begin{align*}
  {\mathbf E} [ X_{n+2} \vert X_1, \ldots, X_n] & = 
     {\mathbf E} [ \phi^2 X_n + \phi Z_{n+1} + Z_{n+2} \vert X_1, \ldots, X_n] \\
     & = \phi^2 \,  {\mathbf E} [ X_{n} \vert X_1, \ldots, X_n]
      +  \phi \, {\mathbf E} [ Z_{n+1} \vert X_1, \ldots, X_n] 
      + {\mathbf E} [ Z_{n+2} \vert X_1, \ldots, X_n]        \\
      & = \phi^2 \, X_n + 0.
\end{align*}
- The prediction error is
\[
 X_{n+2} - \widehat{X}_{n+2} = \phi^2 X_n + \phi Z_{n+1} + Z_{n+2}
  - \phi^2 X_n = \phi Z_{n+1} + Z_{n+2}.
\]
 Hence the prediction MSE is $(1 + \phi^2) \sigma^2$.

```{r}
set.seed(123)
n <- 100
z <- rnorm(n)
x <- rep(0,n)
xhat <- rep(0,n)
phi <- .9
x0 <- 0
x[1] <- x0 + z[1]
x[2] <- phi*x[1] + z[2]
for(t in 3:n) 
{
  x[t] <- phi*x[t-1] + z[t] 
  xhat[t] <- phi^2*x[t-2]
}
plot(ts(x),xlab="Time",ylab="")
lines(ts(xhat),col=2)
```






