---
title: 'Time Series: A First Course with Bootstrap Starter'
output:
  html_document:
    df_print: paged
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Users/neide/OneDrive/Documents/GitHub/BEwebinar/Data')
```

# Lesson 2-4: Autocovariance

- Now we study the autocovariance function.

## Strict and Weak Stationarity

- Strict stationarity: all marginals (of all orders) are time shift invariant.
- Weak stationarity: the time series has finite variance, constant mean $\mu$, and covariance only depends on lag $h$:
\[
  \gamma (h) = \mbox{Cov} [X_t, X_{t-h}] = {\mathbf E} [ X_t \, X_{t-h}] - \mu^2.
\]
This function is called the **autocovariance**.
- So the variance is $\gamma (0)$.
- The **autocorrelation** is
\[
 \rho (h) = \frac{ \gamma (h) }{ \gamma (0)}.
 \]
- Weak stationarity is sometimes called *covariance stationarity*. 
 
## Example: Autocorrelation of an AR(1)

- We plot $\rho (h)$ versus $h$ (on x-axis).
 
```{r}
phi <- .8
rho <- phi^seq(0,20)
plot(ts(rho,start=0),xlab="Lag",ylab="Rho",type ="h")
```

## White Noise

- A key example is a *white noise* stochastic process.
- This is any weakly stationary process $\{ Z_t \}$ with mean zero such that $\gamma (h) = 0$ for $h \neq 0$.
- Written compactly as $Z_t \sim \mbox{WN} (0, \sigma^2)$, where $\sigma^2 = \gamma (0)$ is the variance, and the mean is $\mu = 0$.

## Covariance Matrix of Sample Vector

- The time series variables corresponding to a sample are $X_1, \ldots, X_n$, which can be put into a random vector $\underline{X}$.
- The covariance matrix of $\underline{X}$ is denoted by $\Gamma_n$ when the stochastic process is weakly (or strictly) stationary. The entry in row $j$ and column $k$ is
\[
  \Gamma_n (j,k) = \mbox{Cov} [ X_j, X_k] = \gamma (k-j).
\]
 This only depends on the difference between row and column index! Such a matrix is constant along diagonals, and is called *Toeplitz*.
 
```{r}
rho <- .8
gamma <- rho^seq(0,5)/(1-rho^2)
gamma_mat <- toeplitz(gamma)
gamma_mat
```

## Properties of Autocovariance

1. $\gamma (0) \geq 0$
2. $\gamma (h) = \gamma (-h)$
3. $|\gamma (h)| \leq \gamma (0)$.
4. $\gamma (h)$ is a non-negative definite sequence.

This last property means that $\Gamma_n$ is a non-negative definite matrix for all $n$. (Recall from multivariate analysis: covariance matrices are non-negative definite, and are positive definite if all eigenvalues are positive.)


